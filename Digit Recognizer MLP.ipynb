{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2fa3a4-6ca4-4c48-85fd-7be38d84d50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dc71b9-ef23-49a7-af83-1c2078698b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "                    root=\"data\",\n",
    "                    train=True,\n",
    "                    download=True,\n",
    "                    transform=ToTensor()\n",
    "                )\n",
    "\n",
    "testing_data = datasets.MNIST(\n",
    "                    root=\"data\",\n",
    "                    train=False,\n",
    "                    download=True,\n",
    "                    transform=ToTensor()\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16583e0f-8747-41d1-85fe-ab6f9b0fdb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of training examples: \" + str(len(training_data)))\n",
    "print(\"Number of test instances: \" + str(len(testing_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed87affc-088b-45dc-a173-542357903595",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bf426c-f6aa-4888-b091-12c13ae1707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.linear_relu_softmax_stack = nn.Sequential(\n",
    "        nn.Linear(28*28*1, 350),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(350, 200),\n",
    "        nn.ReLU(),\n",
    "#         nn.Linear(200, 10),\n",
    "#         nn.ReLU(),    \n",
    "        nn.Softmax(dim=1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear_relu_softmax_stack(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47115d58-4d15-4bc5-850c-d73d961a794e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model\n",
    "\n",
    "model = Network()\n",
    "print(model)\n",
    "sample = torch.randn(1,784)\n",
    "model(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b055d3-662c-4326-9a7a-526db245ad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.reshape((1, 784))\n",
    "img.shape\n",
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9789d0c6-424f-4b82-8003-abe61f8df3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(training_data, batch_size=100, shuffle=True)\n",
    "test_dataloader = DataLoader(testing_data, batch_size=100, shuffle=False)\n",
    "for i,(img,label) in enumerate(train_dataloader):\n",
    "    # Flatten the array\n",
    "    img = img.reshape((-1,784))\n",
    "    print(\"i = {}, img = {}, label = {}\".format(i,img.shape,label.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "83ed11f2-2817-426a-8997-f1146236fa75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------Epoch 1:---------------------------\n",
      "Loss : 2.3018312454223633, \tIteration : [100/600]\n",
      "Loss : 2.2955424785614014, \tIteration : [200/600]\n",
      "Loss : 2.280592679977417, \tIteration : [300/600]\n",
      "Loss : 2.195711612701416, \tIteration : [400/600]\n",
      "Loss : 2.21809983253479, \tIteration : [500/600]\n",
      "Loss : 2.0511932373046875, \tIteration : [600/600]\n",
      "\n",
      "---------------------------Epoch 2:---------------------------\n",
      "Loss : 2.028687000274658, \tIteration : [100/600]\n",
      "Loss : 1.8848451375961304, \tIteration : [200/600]\n",
      "Loss : 1.8231468200683594, \tIteration : [300/600]\n",
      "Loss : 1.7065027952194214, \tIteration : [400/600]\n",
      "Loss : 1.6983158588409424, \tIteration : [500/600]\n",
      "Loss : 1.7179397344589233, \tIteration : [600/600]\n",
      "\n",
      "---------------------------Epoch 3:---------------------------\n",
      "Loss : 1.650485634803772, \tIteration : [100/600]\n",
      "Loss : 1.6709375381469727, \tIteration : [200/600]\n",
      "Loss : 1.7145496606826782, \tIteration : [300/600]\n",
      "Loss : 1.6970325708389282, \tIteration : [400/600]\n",
      "Loss : 1.6946842670440674, \tIteration : [500/600]\n",
      "Loss : 1.6356147527694702, \tIteration : [600/600]\n",
      "\n",
      "---------------------------Epoch 4:---------------------------\n",
      "Loss : 1.666100025177002, \tIteration : [100/600]\n",
      "Loss : 1.637319803237915, \tIteration : [200/600]\n",
      "Loss : 1.6029961109161377, \tIteration : [300/600]\n",
      "Loss : 1.7161811590194702, \tIteration : [400/600]\n",
      "Loss : 1.6815621852874756, \tIteration : [500/600]\n",
      "Loss : 1.6525514125823975, \tIteration : [600/600]\n",
      "\n",
      "---------------------------Epoch 5:---------------------------\n",
      "Loss : 1.6219253540039062, \tIteration : [100/600]\n",
      "Loss : 1.6691219806671143, \tIteration : [200/600]\n",
      "Loss : 1.6821476221084595, \tIteration : [300/600]\n",
      "Loss : 1.601696491241455, \tIteration : [400/600]\n",
      "Loss : 1.7202028036117554, \tIteration : [500/600]\n",
      "Loss : 1.6888331174850464, \tIteration : [600/600]\n",
      "\n",
      "---------------------------Epoch 6:---------------------------\n",
      "Loss : 1.6527959108352661, \tIteration : [100/600]\n",
      "Loss : 1.6040253639221191, \tIteration : [200/600]\n",
      "Loss : 1.666627049446106, \tIteration : [300/600]\n",
      "Loss : 1.5935560464859009, \tIteration : [400/600]\n",
      "Loss : 1.593056321144104, \tIteration : [500/600]\n",
      "Loss : 1.6801064014434814, \tIteration : [600/600]\n",
      "\n",
      "---------------------------Epoch 7:---------------------------\n",
      "Loss : 1.6931605339050293, \tIteration : [100/600]\n",
      "Loss : 1.673653244972229, \tIteration : [200/600]\n",
      "Loss : 1.5863662958145142, \tIteration : [300/600]\n",
      "Loss : 1.6360183954238892, \tIteration : [400/600]\n",
      "Loss : 1.619775652885437, \tIteration : [500/600]\n",
      "Loss : 1.5832504034042358, \tIteration : [600/600]\n",
      "\n",
      "---------------------------Epoch 8:---------------------------\n",
      "Loss : 1.6011478900909424, \tIteration : [100/600]\n",
      "Loss : 1.6284854412078857, \tIteration : [200/600]\n",
      "Loss : 1.6263307332992554, \tIteration : [300/600]\n",
      "Loss : 1.5968307256698608, \tIteration : [400/600]\n",
      "Loss : 1.6833488941192627, \tIteration : [500/600]\n",
      "Loss : 1.6086266040802002, \tIteration : [600/600]\n",
      "\n",
      "---------------------------Epoch 9:---------------------------\n",
      "Loss : 1.6747713088989258, \tIteration : [100/600]\n",
      "Loss : 1.6602277755737305, \tIteration : [200/600]\n",
      "Loss : 1.6133222579956055, \tIteration : [300/600]\n",
      "Loss : 1.654807686805725, \tIteration : [400/600]\n",
      "Loss : 1.5828051567077637, \tIteration : [500/600]\n",
      "Loss : 1.6789630651474, \tIteration : [600/600]\n",
      "\n",
      "---------------------------Epoch 10:---------------------------\n",
      "Loss : 1.6613506078720093, \tIteration : [100/600]\n",
      "Loss : 1.644884467124939, \tIteration : [200/600]\n",
      "Loss : 1.66927170753479, \tIteration : [300/600]\n",
      "Loss : 1.6059623956680298, \tIteration : [400/600]\n",
      "Loss : 1.629799485206604, \tIteration : [500/600]\n",
      "Loss : 1.6183404922485352, \tIteration : [600/600]\n",
      "\n",
      "---------------------------Epoch 11:---------------------------\n",
      "Loss : 1.6470407247543335, \tIteration : [100/600]\n",
      "Loss : 1.5695085525512695, \tIteration : [200/600]\n",
      "Loss : 1.6325340270996094, \tIteration : [300/600]\n",
      "Loss : 1.58000910282135, \tIteration : [400/600]\n",
      "Loss : 1.6499035358428955, \tIteration : [500/600]\n",
      "Loss : 1.596221923828125, \tIteration : [600/600]\n",
      "\n",
      "---------------------------Epoch 12:---------------------------\n",
      "Loss : 1.5369136333465576, \tIteration : [100/600]\n",
      "Loss : 1.618941307067871, \tIteration : [200/600]\n",
      "Loss : 1.6537797451019287, \tIteration : [300/600]\n",
      "Loss : 1.6624116897583008, \tIteration : [400/600]\n",
      "Loss : 1.5965133905410767, \tIteration : [500/600]\n",
      "Loss : 1.5538313388824463, \tIteration : [600/600]\n",
      "\n",
      "---------------------------Epoch 13:---------------------------\n",
      "Loss : 1.599135398864746, \tIteration : [100/600]\n",
      "Loss : 1.6206303834915161, \tIteration : [200/600]\n",
      "Loss : 1.598359227180481, \tIteration : [300/600]\n",
      "Loss : 1.6192524433135986, \tIteration : [400/600]\n",
      "Loss : 1.595121145248413, \tIteration : [500/600]\n",
      "Loss : 1.587216854095459, \tIteration : [600/600]\n",
      "\n",
      "---------------------------Epoch 14:---------------------------\n",
      "Loss : 1.6271181106567383, \tIteration : [100/600]\n",
      "Loss : 1.6114028692245483, \tIteration : [200/600]\n",
      "Loss : 1.6425763368606567, \tIteration : [300/600]\n",
      "Loss : 1.557421088218689, \tIteration : [400/600]\n",
      "Loss : 1.6423704624176025, \tIteration : [500/600]\n",
      "Loss : 1.5547056198120117, \tIteration : [600/600]\n",
      "\n",
      "---------------------------Epoch 15:---------------------------\n",
      "Loss : 1.605802297592163, \tIteration : [100/600]\n",
      "Loss : 1.6538740396499634, \tIteration : [200/600]\n",
      "Loss : 1.5574690103530884, \tIteration : [300/600]\n",
      "Loss : 1.6523879766464233, \tIteration : [400/600]\n",
      "Loss : 1.5981101989746094, \tIteration : [500/600]\n",
      "Loss : 1.5666685104370117, \tIteration : [600/600]\n",
      "\n",
      "---------------------------Epoch 16:---------------------------\n",
      "Loss : 1.598260760307312, \tIteration : [100/600]\n",
      "Loss : 1.6028907299041748, \tIteration : [200/600]\n",
      "Loss : 1.5806779861450195, \tIteration : [300/600]\n",
      "Loss : 1.6345710754394531, \tIteration : [400/600]\n",
      "Loss : 1.62876296043396, \tIteration : [500/600]\n",
      "Loss : 1.6492310762405396, \tIteration : [600/600]\n",
      "\n",
      "---------------------------Epoch 17:---------------------------\n",
      "Loss : 1.596136212348938, \tIteration : [100/600]\n",
      "Loss : 1.6424349546432495, \tIteration : [200/600]\n",
      "Loss : 1.5784671306610107, \tIteration : [300/600]\n",
      "Loss : 1.7120959758758545, \tIteration : [400/600]\n",
      "Loss : 1.5826406478881836, \tIteration : [500/600]\n",
      "Loss : 1.5809991359710693, \tIteration : [600/600]\n",
      "\n",
      "---------------------------Epoch 18:---------------------------\n",
      "Loss : 1.6142895221710205, \tIteration : [100/600]\n",
      "Loss : 1.6028541326522827, \tIteration : [200/600]\n",
      "Loss : 1.6101642847061157, \tIteration : [300/600]\n",
      "Loss : 1.6198627948760986, \tIteration : [400/600]\n",
      "Loss : 1.5587053298950195, \tIteration : [500/600]\n",
      "Loss : 1.5886822938919067, \tIteration : [600/600]\n",
      "\n",
      "---------------------------Epoch 19:---------------------------\n",
      "Loss : 1.6063449382781982, \tIteration : [100/600]\n",
      "Loss : 1.6181626319885254, \tIteration : [200/600]\n",
      "Loss : 1.6226783990859985, \tIteration : [300/600]\n",
      "Loss : 1.535763144493103, \tIteration : [400/600]\n",
      "Loss : 1.556565523147583, \tIteration : [500/600]\n",
      "Loss : 1.56642746925354, \tIteration : [600/600]\n",
      "\n",
      "---------------------------Epoch 20:---------------------------\n",
      "Loss : 1.6223959922790527, \tIteration : [100/600]\n",
      "Loss : 1.6010454893112183, \tIteration : [200/600]\n",
      "Loss : 1.5913974046707153, \tIteration : [300/600]\n",
      "Loss : 1.5529115200042725, \tIteration : [400/600]\n",
      "Loss : 1.5964879989624023, \tIteration : [500/600]\n",
      "Loss : 1.6194015741348267, \tIteration : [600/600]\n",
      "\n",
      "Training complete!\n",
      "Testing...\n",
      "Test Accuracy = 86.72999999999999% on 10000 samples\n"
     ]
    }
   ],
   "source": [
    "# Hyper parameters\n",
    "num_of_epochs = 20\n",
    "learning_rate = 0.1\n",
    "batch_size = 100\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(testing_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.linear_relu_softmax_stack = nn.Sequential(\n",
    "        nn.Linear(28*28, 200),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(200, 50),  \n",
    "        nn.ReLU(),\n",
    "        nn.Linear(50, 10),  \n",
    "        nn.ReLU(),\n",
    "            \n",
    "#         Upto 86% Accuracy with 1 hidden layer, 450 nodes, 200 batch size, learning rate = 0.2\n",
    "#         nn.Linear(28*28, 450),\n",
    "#         nn.ReLU(),\n",
    "#         nn.Linear(450, 10),  \n",
    "#         nn.ReLU(),\n",
    "        nn.Softmax(dim=1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear_relu_softmax_stack(x)\n",
    "\n",
    "        return out\n",
    "    \n",
    "# Creating the model\n",
    "model = Network()\n",
    "# print(model)\n",
    "# sample = torch.randn(1,784)\n",
    "# model(sample)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "size = len(training_data)\n",
    "num_iters = len(training_data) / batch_size\n",
    "\n",
    "for epoch in range(num_of_epochs):\n",
    "    print(\"\\n---------------------------Epoch {}:---------------------------\".format(epoch+1))\n",
    "    for i,(imgs,labels) in enumerate(train_dataloader):\n",
    "        # Flatten the array\n",
    "        imgs = imgs.reshape((-1,784))\n",
    "\n",
    "        # Forward propagation (predictions + loss computation)\n",
    "        preds = model(imgs)\n",
    "        loss = loss_fn(preds, labels)\n",
    "\n",
    "        # Backpropagation (calculating gradients + updating weights)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #print(\"Epoch:{}, iteration:{}\".format(epoch,i))\n",
    "        \n",
    "        # Print statistics\n",
    "        if (i + 1) % 100 == 0:\n",
    "            current_batch = i + 1\n",
    "            l = loss.item()\n",
    "\n",
    "            print(\"Loss : {}, \\tIteration : [{}/{}]\".format(l, current_batch,int(num_iters)))\n",
    "print(\"\\nTraining complete!\")\n",
    "print(\"Testing...\")\n",
    "with torch.no_grad():\n",
    "    size = len(test_dataloader.dataset)\n",
    "    correct_labels = 0\n",
    "    for imgs,labels in test_dataloader:\n",
    "        imgs = imgs.reshape((-1,784))\n",
    "        \n",
    "        # Make predictions\n",
    "        preds = model(imgs)\n",
    "        \n",
    "        # Get the predicted labels (indexes with highest probabilities)\n",
    "        _,indexes = torch.max(preds,1)\n",
    "        \n",
    "        # Count the number of correct labels\n",
    "        correct_labels +=  (indexes == labels).type(torch.float).sum().item()\n",
    "    #    print(\"Prediction = {}, Label = {}\".format(pred.shape,label.shape))\n",
    "print(\"Test Accuracy = {}% on {} samples\".format(100 * (correct_labels / size), size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381d96a3-db26-49e8-a1c0-6121f5f290de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc60c1ec-0644-4072-8b62-49eeb40d451c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
